{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Personal Attacks on Wikipedia: Establishing Notebook\n",
    "\n",
    "Courtney Mansfield, Amandalynne Paullada, Tracy Rohlin  \n",
    "LING 575 D/E/F  \n",
    "Spring 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Task: Identify personal attacks in Wikipedia comments.\n",
    "[Wikipedia](wikipedia.org), the online encyclopedia, is maintained by a global community of editors. Each page on Wikipedia has an affiliated [talk page](https://en.wikipedia.org/wiki/Wikipedia:Talk_page_guidelines), where community members can make suggestions for improvement, record changes they've made, or raise an issue about the page's content. However, the interactions on these talk pages can turn sour. Can we train a classifier to recognize hostility in Wikipedia talk page comments?\n",
    "\n",
    "\n",
    "### Data:\n",
    "[>100k labeled comments](https://figshare.com/articles/Wikipedia_Talk_Labels_Personal_Attacks/4054689) from English Wikipedia, each labeled by multiple annotators for whether it contains a personal attack.\n",
    "[Wulczyn](https://arxiv.org/pdf/1610.08914.pdf) et al describes their method of collecting this data and building a classifier. \n",
    "Conveniently, Wulczyn also provides an [IPython Notebook](https://github.com/ewulczyn/wiki-detox/blob/master/src/figshare/Wikipedia%20Talk%20Data%20-%20Getting%20Started.ipynb) outlining their method for training and testing a bag of words classifier on the data. We will adopt their method of labeling a comment as an attack if the majority of raters (mean over ratings > 0.5) call it an attack.\n",
    "\n",
    "**Example benign comment:** \"Thanks man! I will try to improve it.\"  \n",
    "**Example personal attack:** \"shut up mind your own business and go fuck some one else over\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Splitting the data:\n",
    "We will use an 80-10-10 training / dev / test split, ensuring an even proportion of non-attack to attack data in each.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Neural network approach:  \n",
    "\n",
    "[Mehdad & Tetrault](https://pdfs.semanticscholar.org/0f31/0daf6fc761c3bf1649ebab37f8c2e92a857e.pdf) describe a Recurrent Neural Network approach to classify abusive vs. clean posts in Yahoo! forum comment data. Three models are learned: one using tokenized words, one model using character ngrams with 50 layers and 4 backpropagation steps, and the last model using character ngrams with 200 layers and 10 backpropagation steps.\n",
    "\n",
    "\n",
    "### Input iterator\n",
    "The input are low-dimensionality feature vectors where the character embeddings are learned using a skip-gram model using window sizes of 5 and 10. The feature vectors are then transformed using a language model representing ngrams where n = 1...5.  \n",
    "\n",
    "\n",
    "### Loss function  \n",
    "[Karpathy](http://cs231n.github.io/neural-networks-2/#losses) suggests either SVM or softmax as the loss function for classification tasks. We will use the softmax function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Evaluation metric\n",
    "\n",
    "We follow the approach that both Wulczyn et al and Mehrdad & Tetrault use, i.e., Precision, Recall, F1, and AUC values. Token n-grams will be used as a performance baseline to compare with the character-based approach."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
