{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Personal Attacks on Wikipedia: Establishing Notebook\n",
    "\n",
    "Courtney Mansfield, Amandalynne Paullada, Tracy Rohlin  \n",
    "LING 575 D/E/F  \n",
    "Spring 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Task: Identify personal attacks in Wikipedia comments.\n",
    "[Wikipedia](wikipedia.org), the online encyclopedia, is maintained by a global community of editors. Each page on Wikipedia has an affiliated [talk page](https://en.wikipedia.org/wiki/Wikipedia:Talk_page_guidelines), where community members can make suggestions for improvement, record changes they've made, or raise an issue about the page's content. However, the interactions on these talk pages can turn sour. Can we train a classifier to recognize hostility in Wikipedia talk page comments?\n",
    "\n",
    "\n",
    "### Data:\n",
    "[100k labeled comments](https://figshare.com/articles/Wikipedia_Talk_Labels_Personal_Attacks/4054689) from English Wikipedia, each labeled by multiple annotators for whether it contains a personal attack.\n",
    "\n",
    "**Example benign comment:** \"Thanks man! I will try to improve it.\"  \n",
    "**Example personal attack:** \"shut up mind your own business and go fuck some one else over\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data:\n",
    "The data will be randomly mixed and split into an 80-10-10 training-validation-test set.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Evaluation metric\n",
    "\n",
    "The paper [1] uses Precision, Recall, F1, and AUC values.  Token n-grams will be used as a performance baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Neural network approach:  \n",
    "\n",
    "The paper [1] describes a Recurrent Neural Network approach to classify abusive vs. clean posts in Yahoo data. Three models are learned: one using tokenized words, one model using characer ngrams with 50 layers and 4 backpropagation steps (??), and the last model using character ngrams with 200 layers and 10 backpropagation steps.\n",
    "\n",
    "### Input iterator\n",
    "The input are low-dimensionality feature vectors where the embeddings are learned using a skip-gram model using window sizes of 5 and 10. <---????  The feature vectors are then transformed using a language model representing ngrams where n = 1...5.  \n",
    "\n",
    "\n",
<<<<<<< HEAD
    "### Loss function  \n",
    "[Karpathy](http://cs231n.github.io/neural-networks-2/#losses) suggests either SVM or softmax as the loss function for the classification task. Let's go with softmax because it's in the course slides. "
=======
    "### Loss function\n",
    "A cross-entropy loss function will be used for data training."
>>>>>>> f726a6f1ee9ed1e3d38e4f90aa96caeba0292606
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "[1] Mehdad, Yashar and Joel Tetreault. Do Characters Abuse More than Words?.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
