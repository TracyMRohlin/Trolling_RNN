{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk import classify\n",
    "from nltk import NaiveBayesClassifier\n",
    "from nltk import confusionmatrix\n",
    "from nltk import FreqDist\n",
    "from nltk.metrics import scores\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Download annotated comments and annotations.\n",
    "# If you're Tracy, Courtney, or Amandalynne, don't run this step\n",
    "# because you already have the data! If you aren't us, you will\n",
    "# probably need to do this step.\n",
    "# It will take a while.\n",
    "ANNOTATED_COMMENTS_URL = 'https://ndownloader.figshare.com/files/7038044'\n",
    "ANNOTATIONS_URL = 'https://ndownloader.figshare.com/files/7383751'\n",
    "\n",
    "\n",
    "def download_file(url, fname):\n",
    "    urllib.request.urlretrieve(url, fname)\n",
    "\n",
    "# not needed if files already exist in directory\n",
    "#download_file(ANNOTATED_COMMENTS_URL, 'attack_annotated_comments.tsv')\n",
    "#download_file(ANNOTATIONS_URL, 'attack_annotations.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read the data into a Pandas dataframe.\n",
    "comments = pd.read_csv('../attack_annotated_comments.tsv', sep='\\t', index_col=0)\n",
    "annotations = pd.read_csv('../attack_annotations.tsv',  sep='\\t')\n",
    "\n",
    "# Label a comment as an attack if over half of annotators did so.\n",
    "# We can tinker with this threshold later.\n",
    "labels = annotations.groupby('rev_id')['attack'].mean() > 0.5\n",
    "\n",
    "# Join labels and comments\n",
    "comments['attack'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizing...\n"
     ]
    }
   ],
   "source": [
    "print('tokenizing...')\n",
    "\n",
    "tknz = TweetTokenizer()\n",
    "# Preprocess the data -- remove newlines, tabs, quotes\n",
    "# Something to consider: remove Wikipedia style markup (::'s and =='s)\n",
    "comments['comment'] = comments['comment'].apply(lambda x: x.replace(\"NEWLINE_TOKEN\", \" \"))\n",
    "comments['comment'] = comments['comment'].apply(lambda x: x.replace(\"TAB_TOKEN\", \" \"))\n",
    "comments['comment'] = comments['comment'].apply(lambda x: x.replace(\"`\", \" \"))\n",
    "comments['comment'] = comments['comment'].apply(lambda x: tknz.tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# If you would like to use a small data set for debugging\n",
    "#train_data = comments.iloc[0:100]\n",
    "#test_data = comments.iloc[200:210]\n",
    "\n",
    "# Grab the training data (seems to be 60%)\n",
    "train_data = comments.loc[comments['split'] == 'train']\n",
    "dev_data = comments.loc[comments['split'] == 'dev']\n",
    "test_data = comments.loc[comments['split'] == 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# The list of gold-standard labels for the data\n",
    "train_labels = train_data[\"attack\"].tolist()\n",
    "dev_labels = dev_data[\"attack\"].tolist()\n",
    "test_labels = test_data[\"attack\"].tolist()\n",
    "# Put all the training data (comments) into a list\n",
    "train_texts = train_data[\"comment\"].tolist()\n",
    "dev_texts = dev_data[\"comment\"].tolist()\n",
    "test_texts = test_data[\"comment\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def randomly_sample(comments, labels):\n",
    "    # grab all the attacks to see how many we need to match\n",
    "    attack_indices = [i for i in range(len(comments)) if labels[i] == True]\n",
    "    new_training = [comments[i] for i in attack_indices]\n",
    "    new_labels = [labels[i] for i in attack_indices]\n",
    "\n",
    "    # grab all the ones that are not attacks, shuffle them and select the same number of non-attacks\n",
    "    non_attack_indices = [i for i in range(len(comments)) if labels[i] == False]\n",
    "    random.shuffle(non_attack_indices)\n",
    "    for i in range(len(attack_indices)):\n",
    "        new_training.append(comments[i])\n",
    "        new_labels.append(labels[i])\n",
    "\n",
    "    # shuffle the training and labeling so that they're still matched 1:1\n",
    "    shuf_indices = [i for i in range(len(new_training))]\n",
    "    random.shuffle(shuf_indices)\n",
    "    shuffled_training = [new_training[i] for i in shuf_indices]\n",
    "    shuffled_labels = [new_labels[i] for i in shuf_indices]\n",
    "\n",
    "    return shuffled_training, shuffled_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_texts, train_labels = randomly_sample(train_texts, train_labels)\n",
    "dev_texts, dev_labels = randomly_sample(dev_texts, dev_labels)\n",
    "test_texts, test_labels = randomly_sample(test_texts, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating feature sets...\n"
     ]
    }
   ],
   "source": [
    "# Provide definitions for either bag of words or n-gram model\n",
    "print('creating feature sets...')\n",
    "\n",
    "# bag-of-words features\n",
    "def word_feats(words):\n",
    "    return dict([(word, True) for word in words])\n",
    "\n",
    "# word frequency features\n",
    "def word_freq(words):\n",
    "    return dict(FreqDist(words))\n",
    "\n",
    "# Create the training set and test set\n",
    "train_features = [word_freq(x) for x in train_texts]\n",
    "train_set = list(zip(train_features, train_labels))\n",
    "test_features = [word_freq(x) for x in test_texts]\n",
    "test_set = list(zip(test_features, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifying...\n"
     ]
    }
   ],
   "source": [
    "print('classifying...')\n",
    "# Classify and  retreive system labels\n",
    "classifier = NaiveBayesClassifier.train(train_set)\n",
    "sys_label = classifier.classify_many(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.7392960812772134\n",
      "F1: 0.6949692209721927\n",
      "AUC: 0.8409750996015937\n",
      "Prec: 0.9635079458505003\n",
      "Recall: 0.5434926958831341\n"
     ]
    }
   ],
   "source": [
    "# Extract Attack probabilities for AUROC measure\n",
    "sys_prob = [classifier.prob_classify(test_features[j]).prob(True) for j in range(len(test_features))]\n",
    "roc_auc = metrics.roc_auc_score(test_labels, sys_prob)\n",
    "fpr, tpr, threshold = metrics.roc_curve(test_labels, sys_prob)\n",
    "\n",
    "# Evaluation metrics\n",
    "f1 = metrics.f1_score(test_labels, sys_label)\n",
    "accuracy = classify.accuracy(classifier, test_set)\n",
    "precision = metrics.precision_score(test_labels, sys_label)\n",
    "recall = metrics.recall_score(test_labels, sys_label)\n",
    "print('\\nAccuracy: {}\\nF1: {}\\nAUC: {}\\nPrec: {}\\nRecall: {}'.format(accuracy, f1, roc_auc, precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      |             F |\n",
      "      |      T      a |\n",
      "      |      r      l |\n",
      "      |      u      s |\n",
      "      |      e      e |\n",
      "------+---------------+\n",
      " True | <29.7%> 24.9% |\n",
      "False |   1.1% <44.2%>|\n",
      "------+---------------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print confusion matrix\n",
    "cm = confusionmatrix.ConfusionMatrix(test_labels, sys_label)\n",
    "print(cm.pretty_format(sort_by_count=True, show_percents=True, truncate=9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Plot the ROC\n",
    "def plot_ROC(fpr, tpr, roc_auc):\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.savefig(\"NB_word_roc.png\")\n",
    "    \n",
    "plot_ROC(fpr, tpr, roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                    Fuck = 1                True : False  =    181.7 : 1.0\n",
      "                    fuck = 1                True : False  =     99.1 : 1.0\n",
      "                  faggot = 1                True : False  =     91.8 : 1.0\n",
      "                 asshole = 1                True : False  =     82.6 : 1.0\n",
      "                   bitch = 1                True : False  =     70.6 : 1.0\n",
      "                 fucking = 1                True : False  =     61.7 : 1.0\n",
      "                 fucking = 2                True : False  =     59.8 : 1.0\n",
      "                    dick = 1                True : False  =     53.8 : 1.0\n",
      "                 bastard = 1                True : False  =     52.1 : 1.0\n",
      "                    cunt = 1                True : False  =     47.6 : 1.0\n",
      "                   tests = 1               False : True   =     46.3 : 1.0\n",
      "                    suck = 1                True : False  =     45.5 : 1.0\n",
      "           experimenting = 1               False : True   =     43.1 : 1.0\n",
      "                     fag = 1                True : False  =     42.2 : 1.0\n",
      "                   Style = 1               False : True   =     39.4 : 1.0\n",
      "                  Manual = 1               False : True   =     38.0 : 1.0\n",
      "                 Fucking = 1                True : False  =     37.2 : 1.0\n",
      "                    shit = 1                True : False  =     36.5 : 1.0\n",
      "                   pussy = 1                True : False  =     36.1 : 1.0\n",
      "                    SHIT = 1                True : False  =     33.9 : 1.0\n",
      "                   whore = 1                True : False  =     33.9 : 1.0\n",
      "                  fucked = 1                True : False  =     33.4 : 1.0\n",
      "                     ass = 1                True : False  =     31.6 : 1.0\n",
      "                   BITCH = 1                True : False  =     30.1 : 1.0\n",
      "                  fuckin = 1                True : False  =     29.5 : 1.0\n",
      "                   prick = 1                True : False  =     28.4 : 1.0\n",
      "                 welcome = 2               False : True   =     27.3 : 1.0\n",
      "                 propose = 1               False : True   =     27.0 : 1.0\n",
      "                  merged = 1               False : True   =     27.0 : 1.0\n",
      "                    2003 = 1               False : True   =     27.0 : 1.0\n",
      "                YOURSELF = 1                True : False  =     26.2 : 1.0\n",
      "               newcomers = 1               False : True   =     24.9 : 1.0\n",
      "                 parties = 1               False : True   =     24.6 : 1.0\n",
      "                      GO = 1                True : False  =     24.2 : 1.0\n",
      "                retarded = 1                True : False  =     23.7 : 1.0\n",
      "                     YOU = 4                True : False  =     23.4 : 1.0\n",
      "                    Suck = 1                True : False  =     23.4 : 1.0\n",
      "                  toward = 1               False : True   =     23.0 : 1.0\n",
      "                       ~ = 3               False : True   =     22.6 : 1.0\n",
      "                redirect = 1               False : True   =     22.5 : 1.0\n",
      "                    HELL = 1                True : False  =     22.3 : 1.0\n",
      "                    shit = 2                True : False  =     22.0 : 1.0\n",
      "                 located = 1               False : True   =     21.4 : 1.0\n",
      "                     ASS = 1                True : False  =     20.7 : 1.0\n",
      "                  expand = 1               False : True   =     20.6 : 1.0\n",
      "                    pump = 1               False : True   =     20.6 : 1.0\n",
      "                  France = 1               False : True   =     20.6 : 1.0\n",
      "                  FAGGOT = 1                True : False  =     19.6 : 1.0\n",
      "                    WANT = 1                True : False  =     19.6 : 1.0\n",
      "                    BACK = 1                True : False  =     19.6 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(classifier.show_most_informative_features(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
