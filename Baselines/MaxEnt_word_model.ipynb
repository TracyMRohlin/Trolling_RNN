{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk import classify\n",
    "from nltk import FreqDist\n",
    "from nltk import MaxentClassifier\n",
    "from nltk import confusionmatrix\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Download annotated comments and annotations.\n",
    "# If you're Tracy, Courtney, or Amandalynne, don't run this step\n",
    "# because you already have the data! If you aren't us, you will\n",
    "# probably need to do this step.\n",
    "# It will take a while.\n",
    "ANNOTATED_COMMENTS_URL = 'https://ndownloader.figshare.com/files/7038044'\n",
    "ANNOTATIONS_URL = 'https://ndownloader.figshare.com/files/7383751'\n",
    "\n",
    "\n",
    "def download_file(url, fname):\n",
    "    urllib.request.urlretrieve(url, fname)\n",
    "\n",
    "# not needed if files already exist in directory\n",
    "#download_file(ANNOTATED_COMMENTS_URL, 'attack_annotated_comments.tsv')\n",
    "#download_file(ANNOTATIONS_URL, 'attack_annotations.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read the data into a Pandas dataframe.\n",
    "comments = pd.read_csv('../attack_annotated_comments.tsv', sep='\\t', index_col=0)\n",
    "annotations = pd.read_csv('../attack_annotations.tsv',  sep='\\t')\n",
    "\n",
    "# Label a comment as an attack if over half of annotators did so.\n",
    "# We can tinker with this threshold later.\n",
    "labels = annotations.groupby('rev_id')['attack'].mean() > 0.5\n",
    "\n",
    "# Join labels and comments\n",
    "comments['attack'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizing...\n"
     ]
    }
   ],
   "source": [
    "print('tokenizing...')\n",
    "\n",
    "tknz = TweetTokenizer()\n",
    "# Preprocess the data -- remove newlines, tabs, quotes\n",
    "# Something to consider: remove Wikipedia style markup (::'s and =='s)\n",
    "comments['comment'] = comments['comment'].apply(lambda x: x.replace(\"NEWLINE_TOKEN\", \" \"))\n",
    "comments['comment'] = comments['comment'].apply(lambda x: x.replace(\"TAB_TOKEN\", \" \"))\n",
    "comments['comment'] = comments['comment'].apply(lambda x: x.replace(\"`\", \" \"))\n",
    "comments['comment'] = comments['comment'].apply(lambda x: tknz.tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Very small data set for debugging\n",
    "# train_data = comments.iloc[0:100]\n",
    "# test_data = comments.iloc[200:210]\n",
    "\n",
    "# Grab the training data (seems to be 60%)\n",
    "train_data = comments.loc[comments['split'] == 'train']\n",
    "dev_data = comments.loc[comments['split'] == 'dev']\n",
    "test_data = comments.loc[comments['split'] == 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# The list of gold-standard labels for the data\n",
    "train_labels = train_data[\"attack\"].tolist()\n",
    "dev_labels = dev_data[\"attack\"].tolist()\n",
    "test_labels = test_data[\"attack\"].tolist()\n",
    "# Put all the training data (comments) into a list\n",
    "train_texts = train_data[\"comment\"].tolist()\n",
    "dev_texts = dev_data[\"comment\"].tolist()\n",
    "test_texts = test_data[\"comment\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def randomly_sample(comments, labels):\n",
    "    # grab all the attacks to see how many we need to match\n",
    "    attack_indices = [i for i in range(len(comments)) if labels[i] == True]\n",
    "    new_training = [comments[i] for i in attack_indices]\n",
    "    new_labels = [labels[i] for i in attack_indices]\n",
    "\n",
    "    # grab all the ones that are not attacks, shuffle them and select the same number of non-attacks\n",
    "    non_attack_indices = [i for i in range(len(comments)) if labels[i] == False]\n",
    "    random.shuffle(non_attack_indices)\n",
    "    for i in range(len(attack_indices)):\n",
    "        new_training.append(comments[i])\n",
    "        new_labels.append(labels[i])\n",
    "\n",
    "    # shuffle the training and labeling so that they're still matched 1:1\n",
    "    shuf_indices = [i for i in range(len(new_training))]\n",
    "    random.shuffle(shuf_indices)\n",
    "    shuffled_training = [new_training[i] for i in shuf_indices]\n",
    "    shuffled_labels = [new_labels[i] for i in shuf_indices]\n",
    "\n",
    "    return shuffled_training, shuffled_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_texts, train_labels = randomly_sample(train_texts, train_labels)\n",
    "dev_texts, dev_labels = randomly_sample(dev_texts, dev_labels)\n",
    "test_texts, test_labels = randomly_sample(test_texts, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating feature sets...\n"
     ]
    }
   ],
   "source": [
    "print('creating feature sets...')\n",
    "\n",
    "# bag-of-words features\n",
    "def word_feats(words):\n",
    "    return dict([(word, True) for word in words])\n",
    "\n",
    "# word frequency features\n",
    "def word_freq(words):\n",
    "    return dict(FreqDist(words))\n",
    "\n",
    "# Create the training set and test set\n",
    "train_features = [word_freq(x) for x in train_texts]\n",
    "train_set = list(zip(train_features, train_labels))\n",
    "test_features = [word_freq(x) for x in test_texts]\n",
    "test_set = list(zip(test_features, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21670\n"
     ]
    }
   ],
   "source": [
    "features = train_features+test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "vec = DictVectorizer()\n",
    "feats = vec.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_feats = feats[:len(train_texts), :]\n",
    "test_feats = feats[len(train_texts):, :]\n",
    "\n",
    "assert len(train_features) == train_feats.shape[0]\n",
    "assert len(test_features) == test_feats.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifying...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('classifying...')\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(train_feats, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sys_prob = model.predict_proba(test_feats)\n",
    "sys_prob = sys_prob[:, 1:2]\n",
    "sys_labels = model.predict(test_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.96571357841317\n",
      "F1: 0.8875759621877108\n",
      "AUC: 0.9410509296148738\n",
      "Precision: 0.9028159340659341\n",
      "Recall: 0.8728419654714475\n"
     ]
    }
   ],
   "source": [
    "# Extract Attack probabilities for AUROC measure\n",
    "accuracy = model.score(train_feats, train_labels)\n",
    "roc_auc = metrics.roc_auc_score(test_labels, sys_prob)\n",
    "fpr, tpr, threshold = metrics.roc_curve(test_labels, sys_prob)\n",
    "precision = metrics.precision_score(test_labels, sys_labels)\n",
    "recall = metrics.recall_score(test_labels, sys_labels)\n",
    "\n",
    "# Evaluation metrics\n",
    "f1 = metrics.f1_score(test_labels, sys_labels)\n",
    "print('\\nAccuracy: {}\\nF1: {}\\nAUC: {}\\nPrecision: {}\\nRecall: {}'.format(accuracy, f1, roc_auc, precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      |             F |\n",
      "      |      T      a |\n",
      "      |      r      l |\n",
      "      |      u      s |\n",
      "      |      e      e |\n",
      "------+---------------+\n",
      " True | <47.7%>  7.0% |\n",
      "False |   5.2% <40.1%>|\n",
      "------+---------------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print confusion matrix\n",
    "cm = confusionmatrix.ConfusionMatrix(test_labels, sys_labels)\n",
    "print(cm.pretty_format(sort_by_count=True, show_percents=True, truncate=9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Plot the ROC\n",
    "def plot_ROC(fpr, tpr, roc_auc):\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.savefig(\"MaxEnt_word_roc.png\")\n",
    "    \n",
    "plot_ROC(fpr, tpr, roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
