{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk import classify\n",
    "from nltk import NaiveBayesClassifier\n",
    "from nltk import confusionmatrix\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Download annotated comments and annotations.\n",
    "# If you're Tracy, Courtney, or Amandalynne, don't run this step\n",
    "# because you already have the data! If you aren't us, you will\n",
    "# probably need to do this step.\n",
    "# It will take a while.\n",
    "ANNOTATED_COMMENTS_URL = 'https://ndownloader.figshare.com/files/7038044'\n",
    "ANNOTATIONS_URL = 'https://ndownloader.figshare.com/files/7383751'\n",
    "\n",
    "\n",
    "def download_file(url, fname):\n",
    "    urllib.request.urlretrieve(url, fname)\n",
    "\n",
    "# not needed if files already exist in directory\n",
    "#download_file(ANNOTATED_COMMENTS_URL, 'attack_annotated_comments.tsv')\n",
    "#download_file(ANNOTATIONS_URL, 'attack_annotations.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read the data into a Pandas dataframe.\n",
    "comments = pd.read_csv('../attack_annotated_comments.tsv', sep='\\t', index_col=0)\n",
    "annotations = pd.read_csv('../attack_annotations.tsv',  sep='\\t')\n",
    "\n",
    "# Label a comment as an attack if over half of annotators did so.\n",
    "# We can tinker with this threshold later.\n",
    "labels = annotations.groupby('rev_id')['attack'].mean() > 0.5\n",
    "\n",
    "# Join labels and comments\n",
    "comments['attack'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizing...\n"
     ]
    }
   ],
   "source": [
    "print('tokenizing...')\n",
    "\n",
    "tknz = TweetTokenizer()\n",
    "# Preprocess the data -- remove newlines, tabs, quotes\n",
    "# Something to consider: remove Wikipedia style markup (::'s and =='s)\n",
    "comments['comment'] = comments['comment'].apply(lambda x: x.replace(\"NEWLINE_TOKEN\", \" \"))\n",
    "comments['comment'] = comments['comment'].apply(lambda x: x.replace(\"TAB_TOKEN\", \" \"))\n",
    "comments['comment'] = comments['comment'].apply(lambda x: x.replace(\"`\", \" \"))\n",
    "comments['comment'] = comments['comment'].apply(lambda x: tknz.tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# If you would like to use a small data set for debugging\n",
    "#train_data = comments.iloc[0:100]\n",
    "#test_data = comments.iloc[200:210]\n",
    "\n",
    "# Grab the training data (seems to be 60%)\n",
    "train_data = comments.loc[comments['split'] == 'train']\n",
    "dev_data = comments.loc[comments['split'] == 'dev']\n",
    "test_data = comments.loc[comments['split'] == 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# The list of gold-standard labels for the data\n",
    "train_labels = train_data[\"attack\"].tolist()\n",
    "dev_labels = dev_data[\"attack\"].tolist()\n",
    "test_labels = test_data[\"attack\"].tolist()\n",
    "# Put all the training data (comments) into a list\n",
    "train_texts = train_data[\"comment\"].tolist()\n",
    "dev_texts = dev_data[\"comment\"].tolist()\n",
    "test_texts = test_data[\"comment\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def randomly_sample(comments, labels):\n",
    "    # grab all the attacks to see how many we need to match\n",
    "    attack_indices = [i for i in range(len(comments)) if labels[i] == True]\n",
    "    new_training = [comments[i] for i in attack_indices]\n",
    "    new_labels = [labels[i] for i in attack_indices]\n",
    "\n",
    "    # grab all the ones that are not attacks, shuffle them and select the same number of non-attacks\n",
    "    non_attack_indices = [i for i in range(len(comments)) if labels[i] == False]\n",
    "    random.shuffle(non_attack_indices)\n",
    "    for i in range(len(attack_indices)):\n",
    "        new_training.append(comments[i])\n",
    "        new_labels.append(labels[i])\n",
    "\n",
    "    # shuffle the training and labeling so that they're still matched 1:1\n",
    "    shuf_indices = [i for i in range(len(new_training))]\n",
    "    random.shuffle(shuf_indices)\n",
    "    shuffled_training = [new_training[i] for i in shuf_indices]\n",
    "    shuffled_labels = [new_labels[i] for i in shuf_indices]\n",
    "\n",
    "    return shuffled_training, shuffled_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_texts, train_labels = randomly_sample(train_texts, train_labels)\n",
    "dev_texts, dev_labels = randomly_sample(dev_texts, dev_labels)\n",
    "test_texts, test_labels = randomly_sample(test_texts, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating feature sets...\n"
     ]
    }
   ],
   "source": [
    "print('creating feature sets...')\n",
    "\n",
    "# bag-of-words features\n",
    "def word_feats(words):\n",
    "    return dict([(word, True) for word in words])\n",
    "\n",
    "# Create the training set and test set\n",
    "train_features = [word_feats(x) for x in train_texts]\n",
    "train_set = list(zip(train_features, train_labels))\n",
    "test_features = [word_feats(x) for x in test_texts]\n",
    "test_set = list(zip(test_features, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifying...\n"
     ]
    }
   ],
   "source": [
    "print('classifying...')\n",
    "# Classify and  retreive system labels\n",
    "classifier = NaiveBayesClassifier.train(train_set)\n",
    "sys_label = classifier.classify_many(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.7304063860667634\n",
      "F1: 0.6804301075268817\n",
      "AUC: 0.8439699867197875\n"
     ]
    }
   ],
   "source": [
    "# Extract Attack probabilities for AUROC measure\n",
    "sys_prob = [classifier.prob_classify(test_features[j]).prob(True) for j in range(len(test_features))]\n",
    "roc_auc = metrics.roc_auc_score(test_labels, sys_prob)\n",
    "fpr, tpr, threshold = metrics.roc_curve(test_labels, sys_prob)\n",
    "\n",
    "# Evaluation metrics\n",
    "f1 = metrics.f1_score(test_labels, sys_label)\n",
    "accuracy = classify.accuracy(classifier, test_set)\n",
    "print('\\nAccuracy: {}\\nF1: {}\\nAUC: {}'.format(accuracy, f1, roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      |             F |\n",
      "      |      T      a |\n",
      "      |      r      l |\n",
      "      |      u      s |\n",
      "      |      e      e |\n",
      "------+---------------+\n",
      " True | <28.7%> 25.9% |\n",
      "False |   1.0% <44.3%>|\n",
      "------+---------------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print confusion matrix\n",
    "cm = confusionmatrix.ConfusionMatrix(test_labels, sys_label)\n",
    "print(cm.pretty_format(sort_by_count=True, show_percents=True, truncate=9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Plot the ROC\n",
    "def plot_ROC(fpr, tpr, roc_auc):\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.savefig(\"NB_roc.png\")\n",
    "    \n",
    "plot_ROC(fpr, tpr, roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
