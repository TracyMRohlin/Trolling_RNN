{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk import classify\n",
    "from nltk import FreqDist\n",
    "from nltk import MaxentClassifier\n",
    "from nltk import confusionmatrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Download annotated comments and annotations.\n",
    "# If you're Tracy, Courtney, or Amandalynne, don't run this step\n",
    "# because you already have the data! If you aren't us, you will\n",
    "# probably need to do this step.\n",
    "# It will take a while.\n",
    "ANNOTATED_COMMENTS_URL = 'https://ndownloader.figshare.com/files/7038044'\n",
    "ANNOTATIONS_URL = 'https://ndownloader.figshare.com/files/7383751'\n",
    "\n",
    "\n",
    "def download_file(url, fname):\n",
    "    urllib.request.urlretrieve(url, fname)\n",
    "\n",
    "# not needed if files already exist in directory\n",
    "#download_file(ANNOTATED_COMMENTS_URL, 'attack_annotated_comments.tsv')\n",
    "#download_file(ANNOTATIONS_URL, 'attack_annotations.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read the data into a Pandas dataframe.\n",
    "comments = pd.read_csv('../attack_annotated_comments.tsv', sep='\\t', index_col=0)\n",
    "annotations = pd.read_csv('../attack_annotations.tsv',  sep='\\t')\n",
    "\n",
    "# Label a comment as an attack if over half of annotators did so.\n",
    "# We can tinker with this threshold later.\n",
    "labels = annotations.groupby('rev_id')['attack'].mean() > 0.5\n",
    "\n",
    "# Join labels and comments\n",
    "comments['attack'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing...\n"
     ]
    }
   ],
   "source": [
    "print('preprocessing...')\n",
    "\n",
    "# Preprocess the data -- remove newlines, tabs, quotes\n",
    "# Something to consider: remove Wikipedia style markup (::'s and =='s)\n",
    "comments['comment'] = comments['comment'].apply(lambda x: x.replace(\"NEWLINE_TOKEN\", \" \"))\n",
    "comments['comment'] = comments['comment'].apply(lambda x: x.replace(\"TAB_TOKEN\", \" \"))\n",
    "comments['comment'] = comments['comment'].apply(lambda x: x.replace(\"`\", \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Very small data set for debugging\n",
    "# train_data = comments.iloc[0:100]\n",
    "# test_data = comments.iloc[200:210]\n",
    "\n",
    "# Grab the training data (seems to be 60%)\n",
    "train_data = comments.loc[comments['split'] == 'train']\n",
    "dev_data = comments.loc[comments['split'] == 'dev']\n",
    "test_data = comments.loc[comments['split'] == 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# The list of gold-standard labels for the data\n",
    "train_labels = train_data[\"attack\"].tolist()\n",
    "dev_labels = dev_data[\"attack\"].tolist()\n",
    "test_labels = test_data[\"attack\"].tolist()\n",
    "# Put all the training data (comments) into a list\n",
    "train_texts = train_data[\"comment\"].tolist()\n",
    "dev_texts = dev_data[\"comment\"].tolist()\n",
    "test_texts = test_data[\"comment\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def randomly_sample(comments, labels):\n",
    "    # grab all the attacks to see how many we need to match\n",
    "    attack_indices = [i for i in range(len(comments)) if labels[i] == True]\n",
    "    new_training = [comments[i] for i in attack_indices]\n",
    "    new_labels = [labels[i] for i in attack_indices]\n",
    "\n",
    "    # grab all the ones that are not attacks, shuffle them and select the same number of non-attacks\n",
    "    non_attack_indices = [i for i in range(len(comments)) if labels[i] == False]\n",
    "    random.shuffle(non_attack_indices)\n",
    "    for i in range(len(attack_indices)):\n",
    "        new_training.append(comments[i])\n",
    "        new_labels.append(labels[i])\n",
    "\n",
    "    # shuffle the training and labeling so that they're still matched 1:1\n",
    "    shuf_indices = [i for i in range(len(new_training))]\n",
    "    random.shuffle(shuf_indices)\n",
    "    shuffled_training = [new_training[i] for i in shuf_indices]\n",
    "    shuffled_labels = [new_labels[i] for i in shuf_indices]\n",
    "\n",
    "    return shuffled_training, shuffled_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_texts, train_labels = randomly_sample(train_texts, train_labels)\n",
    "dev_texts, dev_labels = randomly_sample(dev_texts, dev_labels)\n",
    "test_texts, test_labels = randomly_sample(test_texts, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating feature sets...\n"
     ]
    }
   ],
   "source": [
    "print('creating feature sets...')\n",
    "from nltk.util import ngrams\n",
    "\n",
    "# word frequency features\n",
    "def char_freq(words):\n",
    "    bigram = ngrams(list(words), 2)\n",
    "    trigram = ngrams(list(words), 3)\n",
    "    fourgram = ngrams(list(words), 4)\n",
    "    fivegram = ngrams(list(words), 5)\n",
    "    \n",
    "    ngram = list(words)\n",
    "    ngram.extend([ \"%s%s\" % x for x in bigram ])\n",
    "    ngram.extend([ \"%s%s%s\" % x for x in trigram ])\n",
    "    ngram.extend([ \"%s%s%s%s\" % x for x in fourgram ])\n",
    "    ngram.extend([ \"%s%s%s%s%s\" % x for x in fivegram ])\n",
    "    return dict(FreqDist(ngram)) \n",
    "\n",
    "# Create the training set and test set\n",
    "train_features = [char_freq(x) for x in train_texts]\n",
    "train_set = list(zip(train_features, train_labels))\n",
    "test_features = [char_freq(x) for x in test_texts]\n",
    "test_set = list(zip(test_features, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "features = train_features+test_features\n",
    "vec = DictVectorizer()\n",
    "feats = vec.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_feats = feats[:len(train_texts), :]\n",
    "test_feats = feats[len(train_texts):, :]\n",
    "\n",
    "assert len(train_features) == train_feats.shape[0]\n",
    "assert len(test_features) == test_feats.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifying...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('classifying...')\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(train_feats, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sys_prob = model.predict_proba(test_feats)\n",
    "sys_prob = sys_prob[:, 1:2]\n",
    "sys_labels = model.predict(test_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.9266617155588563\n",
      "F1: 0.88478655018955\n",
      "AUC: 0.9332323373173971\n",
      "Precision: 0.8785597381342062\n",
      "Recall: 0.8911022576361222\n"
     ]
    }
   ],
   "source": [
    "# Extract Attack probabilities for AUROC measure\n",
    "accuracy = model.score(train_feats, train_labels)\n",
    "roc_auc = metrics.roc_auc_score(test_labels, sys_prob)\n",
    "fpr, tpr, threshold = metrics.roc_curve(test_labels, sys_prob)\n",
    "precision = metrics.precision_score(test_labels, sys_labels)\n",
    "recall = metrics.recall_score(test_labels, sys_labels)\n",
    "\n",
    "# Evaluation metrics\n",
    "f1 = metrics.f1_score(test_labels, sys_labels)\n",
    "print('\\nAccuracy: {}\\nF1: {}\\nAUC: {}\\nPrecision: {}\\nRecall: {}'.format(accuracy, f1, roc_auc, precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      |             F |\n",
      "      |      T      a |\n",
      "      |      r      l |\n",
      "      |      u      s |\n",
      "      |      e      e |\n",
      "------+---------------+\n",
      " True | <45.5%>  9.1% |\n",
      "False |  16.6% <28.7%>|\n",
      "------+---------------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print confusion matrix\n",
    "cm = confusionmatrix.ConfusionMatrix(test_labels, sys_labels)\n",
    "print(cm.pretty_format(sort_by_count=True, show_percents=True, truncate=9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Plot the ROC\n",
    "def plot_ROC(fpr, tpr, roc_auc):\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.savefig(\"MaxEnt_char_roc.png\")\n",
    "    \n",
    "plot_ROC(fpr, tpr, roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
