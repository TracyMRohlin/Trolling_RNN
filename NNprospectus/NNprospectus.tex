%
% File NN_prospectus.tex
%

\documentclass[11pt]{article}
\usepackage{eacl2017}
\usepackage{eacl2017}
\usepackage{url}
\usepackage{latexsym}

\eaclfinalcopy % Uncomment this line for the final submission
%\def\eaclpaperid{***} %  Enter the acl Paper ID here

%\setlength\titlebox{5cm}
% You can expand the titlebox if you need extra space
% to show all the authors. Please do not make the titlebox
% smaller than 5cm (the original size); we will check this
% in the camera-ready version and ask you to change it back.

\newcommand\BibTeX{B{\sc ib}\TeX}

\title{A Neural Network Model for Classifying Attacks on Wikipedia}

\author{Courtney Mansfield \\
  University of Washington \\
  {\tt coman8@uw.edu} \\\And
  Amandalynne Paullada \\
  University of Washington \\
  {\tt email@uw.edu} \\\And 
  Tracy Rohlin\\
  University of Washington \\
  {\tt email2@uw.edu}}

\date{04/18/2017}

\begin{document}
\maketitle
\begin{abstract}
  This project is a replication of a character n-gram model for classifying attacks in Wikipedia comments based on \cite{mehdad}.
\end{abstract}

\section{Introduction}

Here is an introduction to the amazing NN classifier which we have built.\\
\begin{itemize}
  \setlength\itemsep{0em}
\item How it would fit into a business?
\item How it would fit into a research question? 
\item Why is a neural network architecture a good idea?
\end{itemize}

\section{Data and Metrics}

Our Wikipedia data \cite{wulczyn}. I'm not sure about how we should break up the data and metrics section.  For now it is its own section.  Here are things we should describe:\\
\\
Size of train and eval sets \\
Data distribution \\
Collection and protocols \\
Preprocessing or debiasing \\
Data bias WRT “real” task \\


\section{Model Building Methodology}

\subsection{Network Architecture}
A description of the network architecture, including the points listed below:\\
\\
 Loss function in training\\
 Loss function's relation to quality metric \\
 Loss function's relation to other constraints\\
 Network shape\\
 Network dimensions\\
 Architectural choices\\


\subsection{Training Configuration}

A discussion about the training configuration, including the points below: \\
\\
Pretraining? \\
Gradient descent paradigm \\
Batch sizes \\ 
identify hyperparam choices that were *not* explored \\

\subsection{Experimental Variables}
A discussion of what experimental variables we tweaked and what the effect of the changes are.

\section{Evaluation}
Compare our system to other choices and non-neural network implementations.\\
Be sure to provide a few qualitative examples for comparison--can we see any general patterns in the negative results?

\subsection{Experimental Setup}
Our setup. \\

\subsection{Results}
Our results. \\

\subsection{Discussion and Conclusions}
With a focus on future work and the following points: \\
\\
What was harder (or easier) than anticipated? \\ What would you recommend to a VP of engineering deploying your system? \\
What would you recommend to a researcher interested in the network architecture choices you make? \\

\penalty -5000

\bibliographystyle{eacl2017}
\bibliography{NNprospectus} 

\end{document}
